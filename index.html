<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Suvaansh Bhambri</title>
  
  <meta name="author" content="Jon Barron">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:1000px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Suvaansh Bhambri</name>
              </p>
              <p>I am a passionate researcher who is interested in creating AI systems that can learn to observe, reason, and behave in the actual world using 
              	limited data and supervision. I have been working at various research labs all around the globe. 
              </p>
              <p>
              	I have worked on Domain Generalisation with <a href="http://cds.iisc.ac.in/faculty/venky/">Prof. R. Venkatesh Babu</a> at <a href="https://val.cds.iisc.ac.in/">Video Analytics Lab, Indian Institute of Science, Bangalore</a>. Before that, I worked on Embodied AI and Instruction Following in collaboration with <a href="https://ppolon.github.io/">Prof. Jonghyun Choi</a> at <a href="https://yonseivnl.github.io/">Yonsei Vision and Learning Lab</a> and <a href="https://roozbehm.info/">Dr. Roozbeh Mottaghi</a> at <a href="https://prior.allenai.org/">PRIOR, Allen Institute of AI</a>.  
              </p>
              <p>
              	I completed my bachelors at the <a href="https://www.iitr.ac.in/">Indian Institute of Technology Roorkee</a>.
              
              <p style="text-align:center">
                <a href="mailto:suvaanshbhambri@gmail.com">Email</a> &nbsp/&nbsp
                <a href="data/suvaansh_CV.pdf">CV</a> &nbsp/&nbsp
                <!-- <a href="data/JonBarron-bio.txt">Bio</a> &nbsp/&nbsp -->
                <a href="https://scholar.google.com/citations?hl=en&user=UQjAvO8AAAAJ">Google Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/meta_dude">Twitter</a> &nbsp/&nbsp
                <a href="https://github.com/suvaansh">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/Suvaansh.jpeg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/Suvaansh.jpeg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I'm interested in computer vision, machine learning, and their applications in robotics. Much of my research is about domain generalisation and embodied instruction following. More details about my publications are provided below.
                <br><em>* indicates equal contribution</em>
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
					

          <tr onmouseout="dreamfusion_stop()" onmouseover="dreamfusion_start()">
            <td style="padding:10px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/spa_teaser1.png' width="190">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://sites.google.com/view/spa-unida">
                <papertitle>Subsidiary Prototype Alignment for Universal Domain Adaptation</papertitle>
              </a>
              <br>
              <strong>Suvaansh Bhambri*</strong>,
              <a href="https://sites.google.com/view/jogendra/">Jogendra Nath Kundu*</a>,
              <a href="https://akshayk07.weebly.com/">Akshay Kulkarni*</a>,
              <a href="https://www.linkedin.com/in/aroundstar/?originalSubdomain=in">Hiran Sarkar</a>,
              <a href="https://varunjampani.github.io/">Varun Jampani</a>,
              <a href="http://cds.iisc.ac.in/faculty/venky/">R. Venkatesh Babu</a>
              <br>
              <em>NeurIPS</em>, 2022
              <br>
              <a href="https://sites.google.com/view/spa-unida">project page</a>
              /
              <a href="https://arxiv.org/pdf/2210.15909.pdf">arXiv</a>
              <p></p>
              <p>
              We address negative-transfer in Universal DA with BoW-inspired word-prototypes and subsidiary alignment via a word-related pretext task.
              </p>
            </td>
          </tr>


          <tr onmouseout="dreamfusion_stop()" onmouseover="dreamfusion_start()">
            <td style="padding:10px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/sticker_teaser.png' width="190">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://sites.google.com/view/sticker-sfda">
                <papertitle>Concurrent Subsidiary Supervision for Unsupervised Source-Free Domain Adaptation</papertitle>
              </a>
              <br>
              <strong>Suvaansh Bhambri*</strong>,
              <a href="https://sites.google.com/view/jogendra/">Jogendra Nath Kundu*</a>,
              <a href="https://akshayk07.weebly.com/">Akshay Kulkarni*</a>,
              <a href="https://www.linkedin.com/in/aroundstar/?originalSubdomain=in">Hiran Sarkar</a>,
              <a href="https://varunjampani.github.io/">Varun Jampani</a>,
              <a href="http://cds.iisc.ac.in/faculty/venky/">R. Venkatesh Babu</a>
              <br>
              <em>ECCV</em>, 2022
              <br>
              <a href="https://sites.google.com/view/sticker-sfda">project page</a>
              /
              <a href="https://arxiv.org/pdf/2207.13247.pdf">arXiv</a>
              <p></p>
              <p>
              We introduce concurrent subsidiary supervised DA that not only improves unsupervised goal DA but also facilitates source-free DA. We provide theoretical insights for a suitability criteria to identify DA-assistive subsidiary tasks.
              </p>
            </td>
          </tr>

          <tr onmouseout="dreamfusion_stop()" onmouseover="dreamfusion_start()">
            <td style="padding:10px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/mixup_teaser1.png' width="190">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://sites.google.com/view/mixup-sfda">
                <papertitle>Balancing Discriminability and Transferability for Source-Free Domain Adaptation</papertitle>
              </a>
              <br>
              <strong>Suvaansh Bhambri*</strong>,
              <a href="https://sites.google.com/view/jogendra/">Jogendra Nath Kundu*</a>,
              <a href="https://akshayk07.weebly.com/">Akshay Kulkarni*</a>,
              <a href="https://www.linkedin.com/in/deepesh-mehta7/">Deepesh Mehta</a>,
              <a href="https://www.linkedin.com/in/shreyas-kulkarni-551798188/">Shreyas Kulkarni</a>,
              <a href="https://varunjampani.github.io/">Varun Jampani</a>,
              <a href="http://cds.iisc.ac.in/faculty/venky/">R. Venkatesh Babu</a>
              <br>
              <em>ICML</em>, 2022
              <br>
              <a href="https://sites.google.com/view/mixup-sfda">project page</a>
              /
              <a href="https://arxiv.org/pdf/2206.08009.pdf">arXiv</a>
              <p></p>
              <p>
              We analyze Source-Free Domain Adaptation (SFDA) from the perspective of the tradeoff between Discriminability and Transferability, and show that mixup between original and generic-domain translated samples yields an improved tradeoff, which improves the adaptation. 
              </p>
            </td>
          </tr>


          <tr onmouseout="dreamfusion_stop()" onmouseover="dreamfusion_start()">
            <td style="padding:10px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/ast_teaser.png' width="190">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://sites.google.com/view/ast-ocdaseg">
                <papertitle> Amplitude Spectrum Transformation for Open Compound Domain Adaptive Semantic Segmentation </papertitle>
              </a>
              <br>
              <strong>Suvaansh Bhambri*</strong>,
              <a href="https://sites.google.com/view/jogendra/">Jogendra Nath Kundu*</a>,
              <a href="https://akshayk07.weebly.com/">Akshay Kulkarni*</a>,
              <a href="https://varunjampani.github.io/">Varun Jampani</a>,
              <a href="http://cds.iisc.ac.in/faculty/venky/">R. Venkatesh Babu</a>
              <br>
              <em>AAAI</em>, 2022
              <br>
              <a href="https://sites.google.com/view/ast-ocdaseg">project page</a>
              /
              <a href="https://arxiv.org/pdf/2202.04287.pdf">arXiv</a>
              <p></p>
              <p>
              We propose a feature-space Amplitude Spectrum Transformation (AST), based on a analysis of domain discriminability, for improved disentanglement and manipulability of domain characteristics. 
              </p>
            </td>
          </tr>


          <tr onmouseout="dreamfusion_stop()" onmouseover="dreamfusion_start()">
            <td style="padding:10px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/moca_teaser.png' width="190">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2012.03208.pdf">
                <papertitle> Factorizing Perception and Policy for Interactive Instruction Following </papertitle>
              </a>
              <br>
              <strong>Suvaansh Bhambri*</strong>,
              <a href="https://kunalmessi10.github.io/">Kunal Pratap Singh*</a>,
              <a href="https://bhkim94.github.io/">Byeonghwi Kim*</a>,
              <a href="https://roozbehm.info/">Roozbeh Mottaghi</a>,
              <a href="https://ppolon.github.io/">Jonghyun Choi</a>              
              <br>
              <em>ICCV</em>, 2021
              <br>
              <a href="https://arxiv.org/pdf/2012.03208.pdf">arXiv</a>

              <p>
              We propose to factorize perception and policy for embodied interactive instruction following tasks. The work also present an object-centric
              localisation and an obstruction evasion mechanism for the task.
              </p>

              Earlier version presented at <em>Embodied AI workshop at ECCV 2020</em>: 
              <br> <a href="https://arxiv.org/pdf/2012.03208v2.pdf">MOCA: A Modular Object-Centric Approach for Interactive Instruction Following</a>
            </td>
          </tr>         


          <tr onmouseout="dreamfusion_stop()" onmouseover="dreamfusion_start()">
            <td style="padding:10px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/abp_teaser.png' width="190">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://embodied-ai.org/papers/Agent-with-the-Big-Picture.pdf">
                <papertitle> Agent with the Big Picture: Perceiving Surroundings for Interactive Instruction Following </papertitle>
              </a>
              <br>
              <a href="https://bhkim94.github.io/">Byeonghwi Kim</a>,
              <strong>Suvaansh Bhambri</strong>,
              <a href="https://kunalmessi10.github.io/">Kunal Pratap Singh</a>,
              <a href="https://roozbehm.info/">Roozbeh Mottaghi</a>,
              <a href="https://ppolon.github.io/">Jonghyun Choi</a>              
              <br>
              <em>Embodied AI workshop, CVPR</em>, 2021
              <br>
              <a href="https://embodied-ai.org/papers/Agent-with-the-Big-Picture.pdf">arXiv</a>

              <p>
              When performing actions, a small field of view often limits the agent‚Äôs understanding of an environment, leading to poor performance. We propose to exploit surrounding views by additional observations from navigable directions to enlarge the field of view of the agent. 
              </p>
              
            </td>
          </tr>         




		  

        </tbody></table>

				
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Misc</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
					
          <!-- <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/cvf.jpg"></td>
            <td width="75%" valign="center">
              <a href="https://cvpr2022.thecvf.com/area-chairs">Area Chair, CVPR 2022</a>
              <br>
              <a href="http://cvpr2021.thecvf.com/area-chairs">Area Chair & Longuet-Higgins Award Committee Member, CVPR 2021</a>
              <br>
              <a href="http://cvpr2019.thecvf.com/area_chairs">Area Chair, CVPR 2019</a>
              <br>
              <a href="http://cvpr2018.thecvf.com/organizers/area_chairs">Area Chair, CVPR 2018</a>
            </td>
          </tr>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/cs188.jpg" alt="cs188">
            </td>
            <td width="75%" valign="center">
              <a href="http://inst.eecs.berkeley.edu/~cs188/sp11/announcements.html">Graduate Student Instructor, CS188 Spring 2011</a>
              <br>
              <a href="http://inst.eecs.berkeley.edu/~cs188/fa10/announcements.html">Graduate Student Instructor, CS188 Fall 2010</a>
              <br>
              <a href="http://aima.cs.berkeley.edu/">Figures, "Artificial Intelligence: A Modern Approach", 3rd Edition</a>
            </td>
          </tr>
					

          <tr>
            <td align="center" style="padding:20px;width:25%;vertical-align:middle">
							<heading>Basically <br> Blog Posts</heading>
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2112.11687">Squareplus: A Softplus-Like Algebraic Rectifier</a>
              <br>
              <a href="https://arxiv.org/abs/2010.09714">A Convenient Generalization of Schlick's Bias and Gain Functions</a>
              <br>
              <a href="https://arxiv.org/abs/1704.07483">Continuously Differentiable Exponential Linear Units</a>
            </td>
          </tr> -->
					
					
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                
                Template taken from <a href="https://github.com/jonbarron/jonbarron_website"> here </a>.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
